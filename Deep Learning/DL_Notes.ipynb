{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL revolutionized computer vision\n",
    "Use tensorflow and TF implementation of Keras (popular API / interface for DL models)\n",
    "standalone keras library exists but most common to use in TF\n",
    "use keras whilst also features in TF\n",
    "run models asap to get DL xp, then learn theory to fine tune the models\n",
    "deep learning will be on images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images consist of pixels, arranged in rows and columns, a matrix\n",
    "each value represents the darkness in an image. greyscale 2D, just darkness\n",
    "color images have stacks of matrices, BGR. extra dimension 3D. stack of 3 matrices.\n",
    "tensor is another word for a matrix but with n-dimensions, therefore going forwards call matrices tensors\n",
    "todyas DL models apply convolutions (filters) to matrices to pick out certain patterns\n",
    "a convlution is a small tensor which can/could be applied over the main image to identify patterns. provided e.g. of matrix that determines horizontal straight line detector [1.5,1.5][-1.5,-1.5] apply this to straight line get large value, if not tends towards zero\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: You don't directly choose the numbers to go into your convolutions for deep learning... instead the deep learning technique determines what convolutions will be useful from the data (as part of model-training). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changed signs in a matrix to change vertical vs horizontal line conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: Large the convolution the more patterns you can detect. While any one convolution measures only a single pattern, there are more possible convolutions that can be created with large sizes. So there are also more patterns that can be captured with large convolutions.\n",
    "\n",
    "For example, it's possible to create a 3x3 convolution that filters for bright pixels with a dark one in the middle. There is no configuration of a 2x2 convolution that would capture this.\n",
    "\n",
    "On the other hand, anything that can be captured by a 2x2 convolution could also be captured by a 3x3 convolution.\n",
    "\n",
    "Does this mean powerful models require extremely large convolutions? Not necessarily. In the next lesson, you will see how deep learning models put together many convolutions to capture complex patterns... including patterns to complex to be captured by any single convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 2, building models from convolutions: understand haw can combine convolutions to achieve computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map convolution to the image\n",
    "in practice, dont pick numbers that go into convolution they are prepicked / defined using gradient descent and back propogation. can create / apply lots of filters to determine lots of different patterns\n",
    "possible to stack a 2d tensor indicating where horizontal lines are, another 2d tensor showing where vertical lines are, then keep stacking with any other tensors from convolutions\n",
    "moving horizontally across the tensors (row) is the same as moving across the image, column is down\n",
    "then moving across the dimensions,  the channel dimension - and moving through the last dimension takes you from the output of one convolution to the next. This last dimension is called the channel dimension.\n",
    "Here we see a handwritten digit. Below that is it's representation as a matrix or a 2D tensor. Each convolution, we apply to that tensor creates a new 2D tensor. We stack all those 2D testers into a single 3D tensor. For example, we might have a 2D tensor showing where the horizontal lines are. We stack it on top of a 2D tensor showing where the vertical lines are and keep stacking with any other tensors from other convolutions that we have. The result is a representation of the image in three dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply another tensor onto previous layer and repeat, take previous output as new input\n",
    "so first layer in example did horizontal conversion, second did vertical conversion, second layer, some research papers have used up to 1000 layers\n",
    "practical use: object detection, can take a photo and return what is in it. dog cat etc. \n",
    "most research done on IM GENET dataset. competitors use training data to classify models, typically get right approx. 80% of the time\n",
    "predefined data available on kaggle\n",
    "will start with existing model, then go onto transfer learning (use pretrained models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 3: At the end of this lesson, you will be able to write TensorFlow and Keras code to use one of the best models in computer vision.\n",
    "will be using a pretrained dl model to classify what is in a photo\n",
    "pretrained models saved on kaggle, can attach to your workspace akin to datasets\n",
    "put filepaths in list, then use join() \n",
    "need to do some preprocessing, something we can run through our model.\n",
    "do that using read and prep images\n",
    "workflow should be familiar when get to running the model\n",
    "1. load images using the load_img function, keep in a list for now using list comprehension, use a target size argument to specify size / pixelation of image, when model with them.\n",
    "2. convert each image into an array, np.array - so storing images into 3d tensor, stack them in a new dimension, 4d array\n",
    "3. use preprocess_input - perform arithmetic on pixel values to ensure all values between -1 and 1, to ensure consistency. \n",
    "4. (calls should be more used to) specify the model (ResNet50), give the file path\n",
    "5. read_and_prep_images, \n",
    "6. then get predictions same as in scikit learn\n",
    "7. then get predictions, but want to focus on most likely (highest probability for each image) top 3 etc.\n",
    "8. also want to see the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: hot dog image recognizer model\n",
    "exercise was to write code to use pretrained models to choose which works best at hot dog identification, so deploying then measuring accuracy\n",
    "start by creating image paths. provide image directory, use os.path.join() to join files into a list\n",
    "then run an example model, look at images using ipython.display, importing resnet50 and img_to_array\n",
    "create a function called readandprepimages, setting image paths and specifying height and width (so preprocessing stage) setting it to an image array, then defining model with predetermind weights, reading and prepping images, applying model to prepd images, making the predictions, then displaying top 3 predictions\n",
    "visualizing predictions\n",
    "i.) use model predictions to return true or false on if hotdog or not, so pull out top prediction (top=1), pass into a new list and check if =='hotdog' or not\n",
    "then write a function to determine model accuracy as a fraction, so find total number of images (other images + hot dog images), then use previous model to ascertain accurate predictions / total predictions\n",
    "/./ confusion here as thought built previous model to determine what the top prediction was, not if it was correct or not!\n",
    "iii.) use the VGG16 model instead and check its accuracy. so implement the model, then use our previously created function as a benchmark for accuracy / comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
