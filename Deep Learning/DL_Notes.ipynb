{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL revolutionized computer vision\n",
    "Use tensorflow and TF implementation of Keras (popular API / interface for DL models)\n",
    "standalone keras library exists but most common to use in TF\n",
    "use keras whilst also features in TF\n",
    "run models asap to get DL xp, then learn theory to fine tune the models\n",
    "deep learning will be on images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images consist of pixels, arranged in rows and columns, a matrix\n",
    "each value represents the darkness in an image. greyscale 2D, just darkness\n",
    "color images have stacks of matrices, BGR. extra dimension 3D. stack of 3 matrices.\n",
    "tensor is another word for a matrix but with n-dimensions, therefore going forwards call matrices tensors\n",
    "todyas DL models apply convolutions (filters) to matrices to pick out certain patterns\n",
    "a convlution is a small tensor which can/could be applied over the main image to identify patterns. provided e.g. of matrix that determines horizontal straight line detector [1.5,1.5][-1.5,-1.5] apply this to straight line get large value, if not tends towards zero\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: You don't directly choose the numbers to go into your convolutions for deep learning... instead the deep learning technique determines what convolutions will be useful from the data (as part of model-training). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changed signs in a matrix to change vertical vs horizontal line conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: Large the convolution the more patterns you can detect. While any one convolution measures only a single pattern, there are more possible convolutions that can be created with large sizes. So there are also more patterns that can be captured with large convolutions.\n",
    "\n",
    "For example, it's possible to create a 3x3 convolution that filters for bright pixels with a dark one in the middle. There is no configuration of a 2x2 convolution that would capture this.\n",
    "\n",
    "On the other hand, anything that can be captured by a 2x2 convolution could also be captured by a 3x3 convolution.\n",
    "\n",
    "Does this mean powerful models require extremely large convolutions? Not necessarily. In the next lesson, you will see how deep learning models put together many convolutions to capture complex patterns... including patterns to complex to be captured by any single convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 2, building models from convolutions: understand haw can combine convolutions to achieve computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map convolution to the image\n",
    "in practice, dont pick numbers that go into convolution they are prepicked / defined using gradient descent and back propogation. can create / apply lots of filters to determine lots of different patterns\n",
    "possible to stack a 2d tensor indicating where horizontal lines are, another 2d tensor showing where vertical lines are, then keep stacking with any other tensors from convolutions\n",
    "moving horizontally across the tensors (row) is the same as moving across the image, column is down\n",
    "then moving across the dimensions,  the channel dimension - and moving through the last dimension takes you from the output of one convolution to the next. This last dimension is called the channel dimension.\n",
    "Here we see a handwritten digit. Below that is it's representation as a matrix or a 2D tensor. Each convolution, we apply to that tensor creates a new 2D tensor. We stack all those 2D testers into a single 3D tensor. For example, we might have a 2D tensor showing where the horizontal lines are. We stack it on top of a 2D tensor showing where the vertical lines are and keep stacking with any other tensors from other convolutions that we have. The result is a representation of the image in three dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply another tensor onto previous layer and repeat, take previous output as new input\n",
    "so first layer in example did horizontal conversion, second did vertical conversion, second layer, some research papers have used up to 1000 layers\n",
    "practical use: object detection, can take a photo and return what is in it. dog cat etc. \n",
    "most research done on IM GENET dataset. competitors use training data to classify models, typically get right approx. 80% of the time\n",
    "predefined data available on kaggle\n",
    "will start with existing model, then go onto transfer learning (use pretrained models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 3: At the end of this lesson, you will be able to write TensorFlow and Keras code to use one of the best models in computer vision.\n",
    "will be using a pretrained dl model to classify what is in a photo\n",
    "pretrained models saved on kaggle, can attach to your workspace akin to datasets\n",
    "put filepaths in list, then use join() \n",
    "need to do some preprocessing, something we can run through our model.\n",
    "do that using read and prep images\n",
    "workflow should be familiar when get to running the model\n",
    "1. load images using the load_img function, keep in a list for now using list comprehension, use a target size argument to specify size / pixelation of image, when model with them.\n",
    "2. convert each image into an array, np.array - so storing images into 3d tensor, stack them in a new dimension, 4d array\n",
    "3. use preprocess_input - perform arithmetic on pixel values to ensure all values between -1 and 1, to ensure consistency. \n",
    "4. (calls should be more used to) specify the model (ResNet50), give the file path\n",
    "5. read_and_prep_images, \n",
    "6. then get predictions same as in scikit learn\n",
    "7. then get predictions, but want to focus on most likely (highest probability for each image) top 3 etc.\n",
    "8. also want to see the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: hot dog image recognizer model\n",
    "exercise was to write code to use pretrained models to choose which works best at hot dog identification, so deploying then measuring accuracy\n",
    "start by creating image paths. provide image directory, use os.path.join() to join files into a list\n",
    "then run an example model, look at images using ipython.display, importing resnet50 and img_to_array\n",
    "create a function called readandprepimages, setting image paths and specifying height and width (so preprocessing stage) setting it to an image array, then defining model with predetermind weights, reading and prepping images, applying model to prepd images, making the predictions, then displaying top 3 predictions\n",
    "visualizing predictions\n",
    "i.) use model predictions to return true or false on if hotdog or not, so pull out top prediction (top=1), pass into a new list and check if =='hotdog' or not\n",
    "then write a function to determine model accuracy as a fraction, so find total number of images (other images + hot dog images), then use previous model to ascertain accurate predictions / total predictions\n",
    "/./ confusion here as thought built previous model to determine what the top prediction was, not if it was correct or not!\n",
    "iii.) use the VGG16 model instead and check its accuracy. so implement the model, then use our previously created function as a benchmark for accuracy / comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 4: Transfer Learning: build own highly accurate computer vision models for custom purposes, even when have relatively little data:\n",
    "what if have new use cases, and have new use case with different categorisations to the pretrained model\n",
    "can build a new model from scratch for a specific purpose, provide it with 1000s of photos with appropriate labels\n",
    "transfer learning takes what a model learnt when solving one problem and then applies it to a new problem\n",
    "early layers of DL model define simple shapes, later layers detect more complex, last layer makes predictions\n",
    "therefore most early layers are useful as similar low level patterns\n",
    "therefore use most of pretrained resnet model and chance final few layers\n",
    "changing last layer will predict if layer rural vs. urban. \n",
    "so cut off the last layer. then this penultimate layer will contain information about the photo content stored as a series of numbers in a tensor, should be a 1d vector (aka a vector), a series of dots (nodes), first node represents first number, second layer. \n",
    "then want to (in this example) categorise images into two categories - 2 nodes, urban and rural \n",
    "in theory any node in last layer may inform how urban it is. draw connections between nodes to determione relationship. creates the mesh / connection schematic\n",
    "use data to train the last layer of the model. \n",
    "allow all features from one layer to be connected with the prediction layer, call this last layer a DENSE layer\n",
    "could have last layer as just one node, i.e. just urban. e.g. if 80% urban, 20% rural \n",
    "get a score for each category and then apply a function called softmax - which transforms scores to probabilities, all positive and sum to one\n",
    "then use / work with those probabilities.\n",
    "two new packages from Keras\n",
    "sequential - model that is a sequence of layers, one after another, (some exotic models dont fit into this structure), for now all models want to build will be sequential\n",
    "dense - import\n",
    "\n",
    "separate photoes into two cateogires / classes: urban Vs. rural, save as num classes\n",
    "set up a sequential model that we can add layers to, add pretrained resnet50 model,  include_top=False - i.e. to exclude the layer that makes the predictions. weights=weights_path so dont have the weights for the final layer? pooling=avg - if have extra channels then collapse them to a 1d tensor by taking an average across channels\n",
    "should now have a pretrained model that creates the penultimate layer, then add a dense layer to make predictions.\n",
    "need to specify number of nodes in this layer (num_classes),  and then also apply the softmax function to turn it into probablities. \n",
    "then tell it not to train the first layer which is the resnet50 model because that is the one which was pretrained with the imagenet data.\n",
    "now get to compiler command.\n",
    "tells tensorflow how to update the relationships in the dense connection when doing the training with our data\n",
    "have a measure of loss / inaccuracy that we want to minimize, specify as categorical_crossentropy (the same as log loss)\n",
    "use model called stochastic gradient descent (sgd) to minimize the loss function, then ask model to report the accuracy metric, fraction of what correct\n",
    "raw data split between training directory and validation data. (training: Urban, Rural) (validation:urban, rural)\n",
    "usedatagenerator - tool for working with images grouped into directories with a label. create the object in the abstract, tell want to use resnet preprocessing function everytime it reads an image). use for consistency with how originally created.\n",
    "then set the flow - tell it what directory the data it is in, how many images to read at a time, target size of images\n",
    "tell it that we are classifying images into different categories\n",
    "do the same thing to set up how we read the validation data. good for large datasets because we dont have to hold the whole dataset in memory at once. \n",
    "then fit the mode, tell training data comes from train generator, go through 6 steps of 72 images, validaiton data comes from validation, then number that they have and steps. \n",
    "updates the connections in the dense layer\n",
    "\n",
    "will build our own transfer learning model\n",
    "then learn about powerful trick of data augmentation, to improve models with small / medium size datasets.\n",
    "then will explain all the theory behind this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4: Transfer Learning:\n",
    "optimizer determines how we determine the numerical values that make up the model. So it can affect the resulting model and predictions\n",
    "loss determines what goal we optimize when determining numerical values in the model. So it can affect the resulting model and predictions\n",
    "metrics determines only what we print out while the model is being built, but it doesn't affect the model itself.\n",
    "You may not understand all of this yet. That's totally fine for now. It will become clearer in an upcoming lesson (called A Deeper Understanding of Deep Learning).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 5: Data Augmentation:\n",
    "Flip image (mirror) to double dataset\n",
    "do this with horizontal_flip argument\n",
    "typically value with 100s to 1000s of images\n",
    "sometimes the mirror image isnt the same, e.g. of text (STOP sign)\n",
    "judge on case by case basis.\n",
    "other data augmentation techniques; ImageDataGenerator?\n",
    "can crop the photo and shift slightly vertically / horizontally, width_shift_range, and height, can get different variations of this\n",
    "add argument epochs=2, so that it goes through each raw image file twice, data augmentation allows us to use more epochs before we start overfitting and seeing validation scores get worse. validation more reliable on larger datasets\n",
    "is an easier way to get more out of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5: Data Augmentation:\n",
    "adding augmented data to previous rotation model to see if improves model.\n",
    "same code to specify model and compile\n",
    "data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                              horizontal_flip = True,\n",
    "                                              width_shift_range = 0.1,\n",
    "                                              height_shift_range = 0.1)\n",
    "            \n",
    "data augmentation gives us more data to work with so reduces overfitting\n",
    "but dont want to change how test the model, so validation generator will use the image generator without the augmentation. hence can then do a straightforward comparison between the different training procedures.\n",
    "need some thought to configuire which augmentation types we use (rotation e.g. of not being appropriate)\n",
    "\n",
    "my_new_model.fit_generator(\n",
    "        train_generator, # if you don't know what argument goes first, try the hint\n",
    "        epochs = 3,\n",
    "        steps_per_epoch=19,\n",
    "        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 6: Deeper understanding of deep learning:\n",
    "At the end of this lesson, you will understand how stochastic gradient descent and back-propagation are used to set the weights in a deep learning model. These topics are complex, but many experts view them as the most important ideas in deep learning.\n",
    "more technical details: how use sgd to set numeric values, how batch stize and epochs change process\n",
    "diabetes example: input layer: age, weight, blood sugar - connect to predictin layer, develop diabetes in the next year or dont. connect as a dense layer. each input connected with each output. each connection will have weights \n",
    "can calculate the values in the next layer (prediction layer?) weights? using forward propagation, similiar conceptually to calculations did for convulutions in the first video.\n",
    "top node has 3 connected, multiply the weight by the value in the node. so age 50, weight 0.1, then add weight2.value2 + w3.v3\n",
    "get scores at yes and no values, softmax then converts these into probabilities.\n",
    "softmax function discussed more in a notebook?\n",
    "there are also hidden layers, between input and prediction (output)\n",
    "same calculation, wn.vn. fill in values from left to right, input to output\n",
    "in practice however, will apply some nonlinear function between the layers, this helps capture nonlinear relationships and interaction impacts between the variables better. ReLu important? relu...\n",
    "want to understand where weights in connections come from. good ws are the key to making good predictions\n",
    "find w using, loss functions, gradient descent and backward propagation\n",
    "loss function - how good a models predictions are - loss = f(actual, predicted), lower l score the better\n",
    "for any set of data, if model accurate or not, largely a function of weights\n",
    "therefore this is key to model.\n",
    "use sgd to set the weight which minimizes the loss funciton. gradient descent \n",
    "weights affect predictions, which in turn affect the loss. in practice have mutliple weights \n",
    "Loss on Z axis,  w1 and w2 and x and y respectively\n",
    "want to find lowest point on surface (loss) as that provides best model\n",
    "can find via where steepest gradient is, step until cant go down anymore\n",
    "how do you see which way goes down hill? that is backward propagation\n",
    "typically dont use all data for each step, too computationally heavy\n",
    "instead look at some of the data at the time - this is determined by the batch size, no. or rows that we look at\n",
    "if images, no. of images we look at in each step.\n",
    "take a small batch until used all data, one time through the data is called an epoch\n",
    "set number of epoch as an argument\n",
    "back propagation is the process by which we find out which way to change the weight at each step of gradient descent\n",
    "TF does the backward propagation for you\n",
    "how change weights to improve? go back one layer at a time, there is a weight connecting to No output, if a positive number, the higher the weight the more likely to be a No. can increase value and improve loss function? in this specific instance (this person) - but impacts whole model for others, so have to be careful to not overfit\n",
    "involves chain rule from calculus, amount of change determined by learning rate, balance between traiing and potential to miss best weight \n",
    "can use the optimizer='adam' for a special argument in gd. to find the optimum point\n",
    "works the same for convolutional layers \n",
    "iteratively make small "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU: Rectified linear units\n",
    "is the most commonly use activation function in DL models.\n",
    "it returns zero if any negative input, but for any positive value of x it returns that back\n",
    "so f(x)=max(0,x)\n",
    "this allows your model to account for non linearities and interactions very well.\n",
    "purpose of activation functions two-fold:\n",
    "1. help a model account for interaction effects. - which is where variable A impacts a prediction different depending on the value of B.\n",
    "2. help a model account for non linear effects. the effect of increasing the predictor by one is different at different values of that predictor. is non linear if slope not constant\n",
    "so for relu function it is non linear around, slope is either 0 for negative values or 1 for positive values. this seems limited but DL models allow us to create many different types of non linearities from how we combine ReLU nodes.\n",
    "most models include a bias term for each node. which is a constant number dtermined during model training. bias is effectively an intercept? or should be thought of as the error term in the line equation.\n",
    "previous attempts in using the tanh function as the activation function. derivative of the function is very small unless input ni narrow range between -2 and 2. hence harder to do gradient descent. - more layers the bigger the problem - called the vanishing gradient problem.\n",
    "ReLU has derivative of zero over half its range, and is 1 for positive numbers. When training on a reasonable sized batch, there will usually be some data points giving positive values to any given node. So the average derivative is rarely close to 0, which allows gradient descent to keep progressing.\n",
    "alternatives: \"Leaky ReLU\" for negative numbers gradient is non zero but less than 1.\n",
    "That slope is a parameter the user sets when building the model, and it is frequently called  α . For example, if the user sets  α=0.3 , the activation function is f(x) = max(0.3*x, x). This has the theoretical advantage that, by being influenced by x at all values, it may be make more complete use of the information contained in x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 7: DL learning from scratch\n",
    "transfer learning only really useful if pretrained models similar to application\n",
    "hence build from scratch\n",
    "will look at MNIST fashion data?\n",
    "\n",
    "stores all the images in a single csv, each row is an image, each column pixel intensity\n",
    "use dataprep function to extract labels\n",
    "raw.values gives data as a numpy array, reshape into a 4d array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 6: basically just creating own DL Model with following code:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def data_prep(raw):\n",
    "    out_y = keras.utils.to_categorical(raw.label, num_classes)\n",
    "\n",
    "    num_images = raw.shape[0]\n",
    "    x_as_array = raw.values[:,1:]\n",
    "    x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = x_shaped_array / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "train_file = \"../input/digit-recognizer/train.csv\"\n",
    "raw_data = pd.read_csv(train_file)\n",
    "\n",
    "x, y = data_prep(raw_data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 8: Dropout and strides for larger models\n",
    "    how to use stride lengths to make model faster and reduce memory consumption. and dropout to combat overfitting\n",
    "    \n",
    "can slide across and down multiple rows / columns when applying a convolution, if move in two pixels then stride length is 2\n",
    "hence can make model much faster, strides =2, makes 4x faster. can also use max pooling but conceptually trickier to wrap head around\n",
    "also: dropout\n",
    "ignore randomly chosen nodes / convolutions for brief periods of training, then randomly choose to ignore some other ones the next time you train.\n",
    "this minimizes one node domination, or reliance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
