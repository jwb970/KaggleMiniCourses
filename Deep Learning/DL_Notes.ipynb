{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL revolutionized computer vision\n",
    "Use tensorflow and TF implementation of Keras (popular API / interface for DL models)\n",
    "standalone keras library exists but most common to use in TF\n",
    "use keras whilst also features in TF\n",
    "run models asap to get DL xp, then learn theory to fine tune the models\n",
    "deep learning will be on images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images consist of pixels, arranged in rows and columns, a matrix\n",
    "each value represents the darkness in an image. greyscale 2D, just darkness\n",
    "color images have stacks of matrices, BGR. extra dimension 3D. stack of 3 matrices.\n",
    "tensor is another word for a matrix but with n-dimensions, therefore going forwards call matrices tensors\n",
    "todyas DL models apply convolutions (filters) to matrices to pick out certain patterns\n",
    "a convlution is a small tensor which can/could be applied over the main image to identify patterns. provided e.g. of matrix that determines horizontal straight line detector [1.5,1.5][-1.5,-1.5] apply this to straight line get large value, if not tends towards zero\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: You don't directly choose the numbers to go into your convolutions for deep learning... instead the deep learning technique determines what convolutions will be useful from the data (as part of model-training). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changed signs in a matrix to change vertical vs horizontal line conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: Large the convolution the more patterns you can detect. While any one convolution measures only a single pattern, there are more possible convolutions that can be created with large sizes. So there are also more patterns that can be captured with large convolutions.\n",
    "\n",
    "For example, it's possible to create a 3x3 convolution that filters for bright pixels with a dark one in the middle. There is no configuration of a 2x2 convolution that would capture this.\n",
    "\n",
    "On the other hand, anything that can be captured by a 2x2 convolution could also be captured by a 3x3 convolution.\n",
    "\n",
    "Does this mean powerful models require extremely large convolutions? Not necessarily. In the next lesson, you will see how deep learning models put together many convolutions to capture complex patterns... including patterns to complex to be captured by any single convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 2, building models from convolutions: understand haw can combine convolutions to achieve computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map convolution to the image\n",
    "in practice, dont pick numbers that go into convolution they are prepicked / defined using gradient descent and back propogation. can create / apply lots of filters to determine lots of different patterns\n",
    "possible to stack a 2d tensor indicating where horizontal lines are, another 2d tensor showing where vertical lines are, then keep stacking with any other tensors from convolutions\n",
    "moving horizontally across the tensors (row) is the same as moving across the image, column is down\n",
    "then moving across the dimensions,  the channel dimension - and moving through the last dimension takes you from the output of one convolution to the next. This last dimension is called the channel dimension.\n",
    "Here we see a handwritten digit. Below that is it's representation as a matrix or a 2D tensor. Each convolution, we apply to that tensor creates a new 2D tensor. We stack all those 2D testers into a single 3D tensor. For example, we might have a 2D tensor showing where the horizontal lines are. We stack it on top of a 2D tensor showing where the vertical lines are and keep stacking with any other tensors from other convolutions that we have. The result is a representation of the image in three dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply another tensor onto previous layer and repeat, take previous output as new input\n",
    "so first layer in example did horizontal conversion, second did vertical conversion, second layer, some research papers have used up to 1000 layers\n",
    "practical use: object detection, can take a photo and return what is in it. dog cat etc. \n",
    "most research done on IM GENET dataset. competitors use training data to classify models, typically get right approx. 80% of the time\n",
    "predefined data available on kaggle\n",
    "will start with existing model, then go onto transfer learning (use pretrained models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 3: At the end of this lesson, you will be able to write TensorFlow and Keras code to use one of the best models in computer vision.\n",
    "will be using a pretrained dl model to classify what is in a photo\n",
    "pretrained models saved on kaggle, can attach to your workspace akin to datasets\n",
    "put filepaths in list, then use join() \n",
    "need to do some preprocessing, something we can run through our model.\n",
    "do that using read and prep images\n",
    "workflow should be familiar when get to running the model\n",
    "1. load images using the load_img function, keep in a list for now using list comprehension, use a target size argument to specify size / pixelation of image, when model with them.\n",
    "2. convert each image into an array, np.array - so storing images into 3d tensor, stack them in a new dimension, 4d array\n",
    "3. use preprocess_input - perform arithmetic on pixel values to ensure all values between -1 and 1, to ensure consistency. \n",
    "4. (calls should be more used to) specify the model (ResNet50), give the file path\n",
    "5. read_and_prep_images, \n",
    "6. then get predictions same as in scikit learn\n",
    "7. then get predictions, but want to focus on most likely (highest probability for each image) top 3 etc.\n",
    "8. also want to see the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: hot dog image recognizer model\n",
    "exercise was to write code to use pretrained models to choose which works best at hot dog identification, so deploying then measuring accuracy\n",
    "start by creating image paths. provide image directory, use os.path.join() to join files into a list\n",
    "then run an example model, look at images using ipython.display, importing resnet50 and img_to_array\n",
    "create a function called readandprepimages, setting image paths and specifying height and width (so preprocessing stage) setting it to an image array, then defining model with predetermind weights, reading and prepping images, applying model to prepd images, making the predictions, then displaying top 3 predictions\n",
    "visualizing predictions\n",
    "i.) use model predictions to return true or false on if hotdog or not, so pull out top prediction (top=1), pass into a new list and check if =='hotdog' or not\n",
    "then write a function to determine model accuracy as a fraction, so find total number of images (other images + hot dog images), then use previous model to ascertain accurate predictions / total predictions\n",
    "/./ confusion here as thought built previous model to determine what the top prediction was, not if it was correct or not!\n",
    "iii.) use the VGG16 model instead and check its accuracy. so implement the model, then use our previously created function as a benchmark for accuracy / comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 4: Transfer Learning: build own highly accurate computer vision models for custom purposes, even when have relatively little data:\n",
    "what if have new use cases, and have new use case with different categorisations to the pretrained model\n",
    "can build a new model from scratch for a specific purpose, provide it with 1000s of photos with appropriate labels\n",
    "transfer learning takes what a model learnt when solving one problem and then applies it to a new problem\n",
    "early layers of DL model define simple shapes, later layers detect more complex, last layer makes predictions\n",
    "therefore most early layers are useful as similar low level patterns\n",
    "therefore use most of pretrained resnet model and chance final few layers\n",
    "changing last layer will predict if layer rural vs. urban. \n",
    "so cut off the last layer. then this penultimate layer will contain information about the photo content stored as a series of numbers in a tensor, should be a 1d vector (aka a vector), a series of dots (nodes), first node represents first number, second layer. \n",
    "then want to (in this example) categorise images into two categories - 2 nodes, urban and rural \n",
    "in theory any node in last layer may inform how urban it is. draw connections between nodes to determione relationship. creates the mesh / connection schematic\n",
    "use data to train the last layer of the model. \n",
    "allow all features from one layer to be connected with the prediction layer, call this last layer a DENSE layer\n",
    "could have last layer as just one node, i.e. just urban. e.g. if 80% urban, 20% rural \n",
    "get a score for each category and then apply a function called softmax - which transforms scores to probabilities, all positive and sum to one\n",
    "then use / work with those probabilities.\n",
    "two new packages from Keras\n",
    "sequential - model that is a sequence of layers, one after another, (some exotic models dont fit into this structure), for now all models want to build will be sequential\n",
    "dense - import\n",
    "\n",
    "separate photoes into two cateogires / classes: urban Vs. rural, save as num classes\n",
    "set up a sequential model that we can add layers to, add pretrained resnet50 model,  include_top=False - i.e. to exclude the layer that makes the predictions. weights=weights_path so dont have the weights for the final layer? pooling=avg - if have extra channels then collapse them to a 1d tensor by taking an average across channels\n",
    "should now have a pretrained model that creates the penultimate layer, then add a dense layer to make predictions.\n",
    "need to specify number of nodes in this layer (num_classes),  and then also apply the softmax function to turn it into probablities. \n",
    "then tell it not to train the first layer which is the resnet50 model because that is the one which was pretrained with the imagenet data.\n",
    "now get to compiler command.\n",
    "tells tensorflow how to update the relationships in the dense connection when doing the training with our data\n",
    "have a measure of loss / inaccuracy that we want to minimize, specify as categorical_crossentropy (the same as log loss)\n",
    "use model called stochastic gradient descent (sgd) to minimize the loss function, then ask model to report the accuracy metric, fraction of what correct\n",
    "raw data split between training directory and validation data. (training: Urban, Rural) (validation:urban, rural)\n",
    "usedatagenerator - tool for working with images grouped into directories with a label. create the object in the abstract, tell want to use resnet preprocessing function everytime it reads an image). use for consistency with how originally created.\n",
    "then set the flow - tell it what directory the data it is in, how many images to read at a time, target size of images\n",
    "tell it that we are classifying images into different categories\n",
    "do the same thing to set up how we read the validation data. good for large datasets because we dont have to hold the whole dataset in memory at once. \n",
    "then fit the mode, tell training data comes from train generator, go through 6 steps of 72 images, validaiton data comes from validation, then number that they have and steps. \n",
    "updates the connections in the dense layer\n",
    "\n",
    "will build our own transfer learning model\n",
    "then learn about powerful trick of data augmentation, to improve models with small / medium size datasets.\n",
    "then will explain all the theory behind this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4: Transfer Learning:\n",
    "optimizer determines how we determine the numerical values that make up the model. So it can affect the resulting model and predictions\n",
    "loss determines what goal we optimize when determining numerical values in the model. So it can affect the resulting model and predictions\n",
    "metrics determines only what we print out while the model is being built, but it doesn't affect the model itself.\n",
    "You may not understand all of this yet. That's totally fine for now. It will become clearer in an upcoming lesson (called A Deeper Understanding of Deep Learning).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
